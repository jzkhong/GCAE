{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61ee92b-1b9b-468d-a4b4-f5c928072874",
   "metadata": {},
   "source": [
    "# Supporting Function and Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c90f7b-34cd-4421-b8e5-7e9062d088ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import Isomap, TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Reshape, UpSampling2D, Conv2DTranspose, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503e170d-24a6-4caf-8758-002061016535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84f85c8-0329-4d68-a8f8-86e47ac4d3b5",
   "metadata": {},
   "source": [
    "## Data Generation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f49dbccb-c6c9-4078-af38-a6bf15297802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_s_curve(n=3000, noise=0, seed=42):\n",
    "    \"\"\"\n",
    "    Generate a standardized 3D S-Curve dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    n (int): Number of samples.\n",
    "    noise (float): Standard deviation of Gaussian noise.\n",
    "    seed (int): Random seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Scaled 3D coordinates and corresponding colour labels.\n",
    "    \"\"\"\n",
    "    x, y = datasets.make_s_curve(n, noise=noise, random_state=seed)\n",
    "\n",
    "    # Standardise the data\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "    return x_scaled, y\n",
    "\n",
    "def generate_swiss_roll(n=3000, noise=0, seed=42):\n",
    "    \"\"\"\n",
    "    Generate a standardized 3D Swiss Roll dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    n (int): Number of samples.\n",
    "    noise (float): Standard deviation of Gaussian noise.\n",
    "    seed (int): Random seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Scaled 3D coordinates and corresponding colour labels.\n",
    "    \"\"\"\n",
    "    x, y = datasets.make_swiss_roll(n, noise=noise, random_state=seed)\n",
    "\n",
    "    # Standardise the data\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "    return x_scaled, y\n",
    "\n",
    "def generate_simulated_data(n=3000, noise=0, seed=42):\n",
    "    \"\"\"\n",
    "    Generate both S-Curve and Swiss Roll datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    n (int): Number of samples.\n",
    "    noise (float): Standard deviation of Gaussian noise.\n",
    "    seed (int): Random seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Scaled 3D coordinates and corresponding labels for both datasets.\n",
    "    \"\"\"\n",
    "    x_s, y_s = generate_s_curve(n=n, noise=noise, seed=seed)\n",
    "    x_swiss, y_swiss = generate_swiss_roll(n=n, noise=noise, seed=seed)\n",
    "\n",
    "    return (x_s, x_swiss), (y_s, y_swiss)\n",
    "\n",
    "def load_preprocessed_mnist():\n",
    "    \"\"\"\n",
    "    Load and preprocess the MNIST dataset.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Training and test images, flattened training and test images, training and test labels, and unique labels.\n",
    "    \"\"\"\n",
    "    # Load and normalise the fashion mnist dataset\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    x_train = x_train / 255.\n",
    "    x_test = x_test / 255.\n",
    "\n",
    "    # Get distinct label set from training set\n",
    "    unique_labels = set(y_train)\n",
    "\n",
    "    # Reshape the dataset for PCA, Isomap and t-SNE\n",
    "    flatten_x_train = x_train.reshape(-1, 784) \n",
    "    flatten_x_test = x_test.reshape(-1, 784)  \n",
    "\n",
    "    return x_train, x_test, flatten_x_train, flatten_x_test, y_train, y_test, unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3215fc-163e-4093-9900-6bb7eb9f5787",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e2d493-53d6-44de-ba9e-875db1cc5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colour maps\n",
    "jet_cmap = plt.cm.jet\n",
    "viridis_cmap = plt.cm.viridis\n",
    "\n",
    "def plot_3d_datasets(x, y, title, txt, cmap1=viridis_cmap, cmap2=jet_cmap):\n",
    "    \"\"\"\n",
    "    Plot two 3D scatter plots of datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    x (tuple): Two sets of 3D coordinates.\n",
    "    y (tuple): Two sets of corresponding colour labels.\n",
    "    title (str): Title for the figure.\n",
    "    txt (str): Text for figure caption.\n",
    "    cmap1 (Colormap): Colormap for the first dataset. Default to viridis_cmap.\n",
    "    cmap2 (Colormap): Colormap for the second dataset. Default to jet_cmap.\n",
    "    \"\"\"\n",
    "    points1, points2 = x\n",
    "    points_color1, points_color2 = y\n",
    "    x1, y1, z1 = points1.T\n",
    "    x2, y2, z2 = points2.T\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 4)) \n",
    "    # First 3d scatter subplot\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.scatter(x1, y1, z1, c=points_color1, cmap=cmap1, alpha=0.3)\n",
    "    ax1.view_init(azim=-60, elev=12)\n",
    "    ax1.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax1.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax1.zaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    # Second 3d scatter subplot\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    ax2.scatter(x2, y2, z2, c=points_color2, cmap=cmap2, alpha=0.3)\n",
    "    ax2.view_init(azim=-60, elev=12)\n",
    "    ax2.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax2.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax2.zaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    fig.suptitle(title, fontsize='medium')\n",
    "    fig.text(.5, .05, txt, ha='center')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualise_sample_images(x, y, txt='Figure 5: 10 randomly sampled images from the MNIST training dataset.'):\n",
    "    \"\"\"\n",
    "    Visualize a sample of images with labels.\n",
    "    \n",
    "    Parameters:\n",
    "    x (array): Array of images.\n",
    "    y (array): Array of corresponding labels.\n",
    "    txt (str): Text for figure caption.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 2))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    for i in range(10):\n",
    "        ax = fig.add_subplot(1, 10, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(x[i], cmap=plt.cm.binary)\n",
    "        # label the image with the target value\n",
    "        ax.text(12, -1.5, str(y[i]))\n",
    "    fig.text(.5, .1, txt, ha='center')\n",
    "    fig.tight_layout()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0087d-7a46-443e-b0ef-cd9b70997620",
   "metadata": {},
   "source": [
    "## PCA, Isomap and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "035ac2d3-2315-4bea-8d3c-ae102796052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_multiple_dim_reduction(x_data, y_data, dataset, n_comp, n_neighb, cmap, \n",
    "                                   txt='Figure 2: Dimensionality reduction results for the S-Curve (Top) and ' \n",
    "                                       'Swiss Roll (Bottom) datasets using PCA, Isomap, and t-SNE.'):\n",
    "    \"\"\"\n",
    "    Perform multiple dimensionality reduction techniques (PCA, Isomap & t-SNE) on datasets and plot the results.\n",
    "    \n",
    "    Parameters:\n",
    "    x_data (list): List of datasets to be reduced.\n",
    "    y_data (list): List of corresponding colour labels for each dataset.\n",
    "    dataset (list): List of dataset names.\n",
    "    n_comp (int): Number of components for the dimensionality reduction (used in Isomap & t-SNE).\n",
    "    n_neighb (int): Number of neighbors for Isomap.\n",
    "    cmap (list): List of colormaps for each dataset.\n",
    "    txt (str): Text for figure caption.\n",
    "    \"\"\"\n",
    "    num_dataset = len(x_data)\n",
    "    fig = plt.figure(figsize=(14,6))\n",
    "    counter = 0\n",
    "    # Loop through each dataset\n",
    "    for i, x in enumerate(x_data):\n",
    "        y = y_data[i]\n",
    "        \n",
    "        # Perform PCA \n",
    "        pca = decomposition.PCA()\n",
    "        pca.fit(x)\n",
    "        x_pca = pca.transform(x)\n",
    "        # Visualise the first two principal components for each dataset\n",
    "        counter+=1\n",
    "        plt.subplot(num_dataset, 3, counter)\n",
    "        plt.scatter(x_pca[:, 0], x_pca[:, 1], c=y, cmap=cmap[i], alpha=0.3)\n",
    "        plt.xlabel('PC1')\n",
    "        plt.ylabel('PC2')\n",
    "        plt.title(f'Principal Component Analysis: {dataset[i]}')\n",
    "        \n",
    "        # Perform Isomap\n",
    "        isomap = Isomap(n_components=n_comp, n_neighbors=n_neighb) \n",
    "        x_isomap = isomap.fit_transform(x)\n",
    "        # Visualise the first two dimensions of Isomap embeddings\n",
    "        counter+=1\n",
    "        plt.subplot(num_dataset, 3, counter)\n",
    "        plt.scatter(x_isomap[:, 0], x_isomap[:, 1], c=y, cmap=cmap[i], alpha=0.3)\n",
    "        plt.xlabel('Dim1')\n",
    "        plt.ylabel('Dim2')\n",
    "        plt.title(f'Isomap Embeddings: {dataset[i]}')\n",
    "\n",
    "        # Perform t-SNE\n",
    "        tsne = TSNE(n_components=n_comp) \n",
    "        x_tsne = tsne.fit_transform(x)\n",
    "        # Visualise the first two dimensions of t-SNE embeddings\n",
    "        counter+=1\n",
    "        plt.subplot(num_dataset, 3, counter)\n",
    "        plt.scatter(x_tsne[:, 0], x_tsne[:, 1], c=y, cmap=cmap[i], alpha=0.3)\n",
    "        plt.xlabel('Dim1')\n",
    "        plt.ylabel('Dim2')\n",
    "        plt.title(f't-SNE Embeddings: {dataset[i]}')\n",
    "\n",
    "    fig.text(.5, -0.01, txt, ha='center', fontsize='large')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def perform_mnist_dim_reduction(x, y, n, n_comp, n_neighb, distinct_labels, \n",
    "                                txt='Figure 6: Dimensionality reduction results for the MNIST dataset using PCA,'\n",
    "                                ' Isomap, and t-SNE. Each point represents a MNIST digit in the reduced 2D space,'\n",
    "                                ' colored by its digit class.'):\n",
    "    \"\"\"\n",
    "    Perform dimensionality reduction techniques (PCA, Isomap & t-SNE) on the MNIST dataset and plot the results.\n",
    "    \n",
    "    Parameters:\n",
    "    x (array): Array of MNIST images (flattened).\n",
    "    y (array): Array of corresponding labels.\n",
    "    n (int): Number of samples to visualize.\n",
    "    n_comp (int): Number of components for the dimensionality reduction (used in Isomap & t-SNE).\n",
    "    n_neighb (int): Number of neighbors for Isomap.\n",
    "    cmap (list): List of colormaps for each dataset.\n",
    "    distinct_labels (set): Set of distinct labels in the dataset.\n",
    "    txt (str): Text for figure caption.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "\n",
    "    # Standardise data before performing PCA\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "    # Perform PCA \n",
    "    pca = decomposition.PCA()\n",
    "    pca.fit(x)\n",
    "    x_pca = pca.transform(x_scaled)\n",
    "    \n",
    "    # Visualise the first two principal components for each dataset\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for i in distinct_labels:\n",
    "        plt.scatter(x_pca[:n][y[:n] == i, 0], x_pca[:n][y[:n] == i, 1], label=i, alpha=0.6)\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title('Principal Component Analysis: MNIST')\n",
    "    plt.legend()\n",
    "\n",
    "    # Perform Isomap\n",
    "    isomap = Isomap(n_components=n_comp, n_neighbors=n_neighb) \n",
    "    x_isomap = isomap.fit_transform(x)\n",
    "    \n",
    "    # Visualise the first two dimensions of Isomap embeddings\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for i in distinct_labels:\n",
    "        plt.scatter(x_isomap[:n][y[:n] == i, 0], x_isomap[:n][y[:n] == i, 1], label=i, alpha=0.6)\n",
    "    plt.xlabel('Dim1')\n",
    "    plt.ylabel('Dim2')\n",
    "    plt.title('Isomap Embeddings: MNIST')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Perform t-SNE\n",
    "    tsne = TSNE(n_components=n_comp) \n",
    "    x_tsne = tsne.fit_transform(x)\n",
    "\n",
    "    # Visualise the first two dimensions of t-SNE embeddings\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for i in distinct_labels:\n",
    "        plt.scatter(x_tsne[:n][y[:n] == i, 0], x_tsne[:n][y[:n] == i, 1], label=i, alpha=0.6)\n",
    "    plt.xlabel('Dim1')\n",
    "    plt.ylabel('Dim2')\n",
    "    plt.title('t-SNE Embeddings: MNIST')\n",
    "    plt.legend()\n",
    "\n",
    "    fig.text(.5, -0.01, txt, ha='center', fontsize='large')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ee80e-5a0d-41e3-bc8a-377f1c2ef287",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ff4d17-b943-4bdf-9fb9-1a2354a693e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(input_dim, encoded_dim, dataset, seed=5):\n",
    "    \"\"\"\n",
    "    Define the encoder part of an autoencoder.\n",
    "    \n",
    "    Parameters:\n",
    "    input_dim (int): Dimension of the input data.\n",
    "    encoded_dim (int): Dimension of the encoded representation.\n",
    "    dataset (str): Name of the dataset.\n",
    "    seed (int): Random seed for weight initialization.\n",
    "    \n",
    "    Returns:\n",
    "    Model: Encoder model.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(128, activation='relu', kernel_initializer=GlorotUniform(seed=seed))(inputs)\n",
    "    x = Dense(64, activation='relu', kernel_initializer=GlorotUniform(seed=seed))(x)\n",
    "    encoded = Dense(encoded_dim, activation='relu', kernel_initializer=GlorotUniform(seed=seed))(x)\n",
    "    encoder = Model(inputs, encoded, name=f'{dataset}_encoder')\n",
    "    return encoder\n",
    "\n",
    "def get_decoder(input_dim, encoded_dim, dataset, seed=5):\n",
    "    \"\"\"\n",
    "    Define the decoder part of an autoencoder.\n",
    "    \n",
    "    Parameters:\n",
    "    input_dim (int): Dimension of the output data.\n",
    "    encoded_dim (int): Dimension of the encoded representation.\n",
    "    dataset (str): Name of the dataset.\n",
    "    seed (int): Random seed for weight initialization.\n",
    "    \n",
    "    Returns:\n",
    "    Model: Decoder model.\n",
    "    \"\"\"\n",
    "    encoded_inputs = Input(shape=(encoded_dim,))\n",
    "    x = Dense(64, activation='relu', kernel_initializer=GlorotUniform(seed=seed))(encoded_inputs)\n",
    "    x = Dense(128, activation='relu', kernel_initializer=GlorotUniform(seed=seed))(x)\n",
    "    decoded = Dense(input_dim, kernel_initializer=GlorotUniform(seed=seed))(x)\n",
    "    decoder = Model(encoded_inputs, decoded, name=f'{dataset}_decoder')\n",
    "    return decoder\n",
    "    \n",
    "def get_autoencoder(input_dim, encoded_dim, dataset, seed=5):\n",
    "    \"\"\"\n",
    "    Construct the complete autoencoder by combining encoder and decoder.\n",
    "    \n",
    "    Parameters:\n",
    "    input_dim (int): Dimension of the input data.\n",
    "    encoded_dim (int): Dimension of the encoded representation.\n",
    "    dataset (str): Name of the dataset.\n",
    "    seed (int): Random seed for weight initialization.\n",
    "    \n",
    "    Returns:\n",
    "    Model: Autoencoder model.\n",
    "    \"\"\"\n",
    "    encoder = get_encoder(input_dim, encoded_dim, dataset, seed=seed)\n",
    "    decoder = get_decoder(input_dim, encoded_dim, dataset, seed=seed)\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    encoded = encoder(inputs)\n",
    "    decoded = decoder(encoded)\n",
    "    autoencoder = Model(inputs=inputs, outputs=decoded, name=f'{dataset}_autoencoder')\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b89fec1-76a0-4acf-8379-455694b5b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(x, autoencoder, epochs=100, batch_size=16, validation_split=0.1):\n",
    "    \"\"\"\n",
    "    Train an autoencoder model with adam optimizer and mean squared error loss function.\n",
    "    \n",
    "    Parameters:\n",
    "    x (array): Input data for training.\n",
    "    autoencoder (Model): Autoencoder model to be trained.\n",
    "    epochs (int): Number of training epochs.\n",
    "    batch_size (int): Size of the training batches.\n",
    "    validation_split (float): Fraction of the data to be used as validation data.\n",
    "    \n",
    "    Returns:\n",
    "    History: Training history of the autoencoder.\n",
    "    \"\"\"\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    history = autoencoder.fit(x, x, epochs=100, batch_size=16, validation_split=0.1, verbose=0)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f04053a-2d7c-47d6-947d-0ece85293ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_latent_encodings(x, autoencoder, dataset):\n",
    "    \"\"\"\n",
    "    Compute the latent encodings using a trained autoencoder.\n",
    "    \n",
    "    Parameters:\n",
    "    x (array): Input data to be encoded.\n",
    "    autoencoder (Model): Trained autoencoder model.\n",
    "    dataset (str): Name of the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    array: Latent encodings of the input data.\n",
    "    \"\"\"\n",
    "    encoder = autoencoder.get_layer(f'{dataset}_encoder')\n",
    "    trained_encodings = encoder(x).numpy()\n",
    "    return trained_encodings\n",
    "\n",
    "def visualise_latent_encodings(encodings1, y1, dataset1, encodings2, y2, dataset2, cmap1=viridis_cmap, cmap2=jet_cmap, \n",
    "                               txt='Figure 4: Latent 2D embeddings of the S-Curve (left) and Swiss Roll (right) '\n",
    "                               'datasets from the trained autoencoders.'):\n",
    "    \"\"\"\n",
    "    Generate scatter plots for the latent encodings of two datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    encodings1 (array): Latent encodings for the first dataset.\n",
    "    y1 (array): Labels for the first dataset.\n",
    "    dataset1 (str): Name of the first dataset.\n",
    "    encodings2 (array): Latent encodings for the second dataset.\n",
    "    y2 (array): Labels for the second dataset.\n",
    "    dataset2 (str): Name of the second dataset.\n",
    "    txt (str): Text for figure caption.\n",
    "    cmap1 (Colormap): Colormap for the first dataset. Default to viridis_cmap.\n",
    "    cmap2 (Colormap): Colormap for the second dataset. Default to jet_cmap.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(8,3))\n",
    "    \n",
    "    # Plot the latent encodings for the first dataset\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.scatter(encodings1[:, 0], encodings1[:, 1], c=y1, cmap=cmap1, alpha=0.3)\n",
    "    plt.xlabel('Dim 1')\n",
    "    plt.ylabel('Dim 2')\n",
    "    plt.title(f'Latent Embeddings: {dataset1}')\n",
    "\n",
    "    # Plot the latent encodings for the second dataset\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(encodings2[:, 0], encodings2[:, 1], c=y2, cmap=cmap2, alpha=0.3)\n",
    "    plt.xlabel('Dim 1')\n",
    "    plt.ylabel('Dim 2')\n",
    "    plt.title(f'Latent Embeddings: {dataset2}')\n",
    "    fig.text(.5, .001, txt, ha='center')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130f176-7b8e-431a-a45b-1951513a675c",
   "metadata": {},
   "source": [
    "## CNN Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "502770fd-a4cb-46bf-a131-a22a5fa4415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_encoder(input_shape, encoded_dim, dataset, seed=5):\n",
    "    \"\"\"\n",
    "    Define the CNN encoder part of a CNN autoencoder.\n",
    "    \n",
    "    Parameters:\n",
    "    input_shape (tuple): Shape of the input data.\n",
    "    encoded_dim (int): Dimension of the encoded representation.\n",
    "    dataset (str): Name of the dataset.\n",
    "    seed (int): Random seed for weight initialization.\n",
    "    \n",
    "    Returns:\n",
    "    Model: CNN encoder model.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(input_shape))\n",
    "    x = Conv2D(32, 3, activation='relu', strides=2, padding='same', \n",
    "               kernel_initializer=GlorotUniform(seed=seed))(inputs)\n",
    "    x = Conv2D(64, 3, activation='relu', strides=2, padding='same', \n",
    "               kernel_initializer=GlorotUniform(seed=seed))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu', kernel_initializer=GlorotUniform(seed=seed))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    encoded = Dense(encoded_dim, kernel_initializer=GlorotUniform(seed=seed))(x)\n",
    "    cnn_encoder = Model(inputs, encoded, name=f'{dataset}_cnn_encoder')\n",
    "    return cnn_encoder\n",
    "\n",
    "def get_cnn_decoder(input_shape, encoded_dim, dataset, seed=5):\n",
    "    \"\"\"\n",
    "    Define the CNN decoder part of a CNN autoencoder.\n",
    "    \n",
    "    Parameters:\n",
    "    input_shape (tuple): Shape of the output data.\n",
    "    encoded_dim (int): Dimension of the encoded representation.\n",
    "    dataset (str): Name of the dataset.\n",
    "    seed (int): Random seed for weight initialization.\n",
    "    \n",
    "    Returns:\n",
    "    Model: CNN decoder model.\n",
    "    \"\"\"\n",
    "    encoded_inputs = Input(shape=(encoded_dim,))\n",
    "    x = Dense(64, activation='relu', kernel_initializer=GlorotUniform(seed=seed))(encoded_inputs)\n",
    "    x = Dense(7*7*64, activation='relu', kernel_initializer=GlorotUniform(seed=seed))(x)\n",
    "    x = Reshape((7, 7, 64))(x)\n",
    "    x = Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same', \n",
    "                        kernel_initializer=GlorotUniform(seed=seed))(x)\n",
    "    decoded = Conv2DTranspose(input_shape[-1], 3, activation='sigmoid', strides=2, padding='same', \n",
    "                              kernel_initializer=GlorotUniform(seed=seed))(x)\n",
    "    cnn_decoder = Model(encoded_inputs, decoded, name=f'{dataset}_cnn_decoder')\n",
    "    return cnn_decoder\n",
    "    \n",
    "def get_cnn_autoencoder(input_shape, encoded_dim, dataset, seed=5):\n",
    "    \"\"\"\n",
    "    Construct the complete CNN autoencoder by combining the CNN encoder and CNN decoder.\n",
    "    \n",
    "    Parameters:\n",
    "    input_shape (tuple): Shape of the input data.\n",
    "    encoded_dim (int): Dimension of the encoded representation.\n",
    "    dataset (str): Name of the dataset.\n",
    "    seed (int): Random seed for weight initialization.\n",
    "    \n",
    "    Returns:\n",
    "    Model: CNN autoencoder model.\n",
    "    \"\"\"\n",
    "    cnn_encoder = get_cnn_encoder(input_shape, encoded_dim, dataset, seed=seed)\n",
    "    cnn_decoder = get_cnn_decoder(input_shape, encoded_dim, dataset, seed=seed)\n",
    "    inputs = Input(shape=(input_shape))\n",
    "    encoded = cnn_encoder(inputs)\n",
    "    decoded = cnn_decoder(encoded)\n",
    "    autoencoder = Model(inputs=inputs, outputs=decoded, name=f'{dataset}_cnn_autoencoder')\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ffdcdd2-67fd-4495-b7d0-8fae180fd70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn_autoencoder(x_train, x_test, cnn_autoencoder, epochs=100, batch_size=64, buffer_size =1000):\n",
    "    \"\"\"\n",
    "    Train a CNN autoencoder model with adam optimizer and mean squared error loss function. \n",
    "    The model is trained with a early stopping if validation loss doesn't improve after 10 epochs.\n",
    "    \n",
    "    Parameters:\n",
    "    x_train (array): Training data.\n",
    "    x_test (array): Testing data.\n",
    "    cnn_autoencoder (Model): CNN autoencoder model to be trained.\n",
    "    epochs (int): Number of training epochs.\n",
    "    batch_size (int): Size of the training batches.\n",
    "    buffer_size (int): Buffer size for shuffling the training data.\n",
    "    \n",
    "    Returns:\n",
    "    History: Training history of the CNN autoencoder.\n",
    "    \"\"\"\n",
    "    # Create Tensorflow Dataset objects for train and test sets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, x_train))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, x_test))\n",
    "    \n",
    "    # Shuffle and batch the datasets\n",
    "    shuffle_buffer_size = buffer_size\n",
    "    batch_size = batch_size\n",
    "    train_dataset = train_dataset.shuffle(shuffle_buffer_size, seed).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Create an EarlyStopping callback to terminate training if the val_loss doesn't immprove after 10 epochs\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                                   patience=10, \n",
    "                                   mode='min', \n",
    "                                   restore_best_weights=True)\n",
    "    \n",
    "    # Train the autoencoder with adam optimizer and mean squared error loss function with early stopping\n",
    "    cnn_autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    history = cnn_autoencoder.fit(train_dataset, \n",
    "                                  epochs=epochs,\n",
    "                                  validation_data=test_dataset, \n",
    "                                  callbacks=early_stopping, \n",
    "                                  verbose=0)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b037715-5d61-4610-bdb4-764da1b601d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_ten_images(x, cnn_autoencoder, seed=19, \n",
    "                           txt='Figure 7: Comparison of 10 original (Top) vs. reconstructed (Bottom) '\n",
    "                           'images randomly sampled from the MNIST test dataset.'):\n",
    "    \"\"\"\n",
    "    Randomly sample and reconstruct 10 images using a trained CNN autoencoder. \n",
    "    Plot the original and reconstructed images for comparison.\n",
    "    \n",
    "    Parameters:\n",
    "    x (array): Input images for reconstruction.\n",
    "    cnn_autoencoder (Model): Trained CNN autoencoder model.\n",
    "    seed (int): Random seed for reproducibility.\n",
    "    txt (str): Text for figure caption.\n",
    "    \"\"\"\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Randomly sample and reconstruct 10 images\n",
    "    inx = np.random.choice(x.shape[0], 10, replace=False)\n",
    "    reconstructed_images = cnn_autoencoder(x[inx])\n",
    "\n",
    "    # Examine reconstructions vs original images\n",
    "    f, axs = plt.subplots(2, 10, figsize=(9, 2))\n",
    "    for j in range(10):\n",
    "        axs[0, j].imshow(x[inx][j], cmap='binary')\n",
    "        axs[1, j].imshow(reconstructed_images[j].numpy().squeeze(), cmap='binary')\n",
    "        axs[0, j].axis('off')\n",
    "        axs[1, j].axis('off')\n",
    "    f.text(.5, .001, txt, ha='center')\n",
    "    plt.suptitle('MNIST Reconstructions', fontsize='medium')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c5c8b9-2a79-4bde-9813-db21ad960475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_mnist_latent_encodings(x, y, cnn_autoencoder, n, \n",
    "                                   txt='Figure 8: Latent 2D embeddings of the MNIST dataset from '\n",
    "                                   'the trained CNN autoencoder.'):\n",
    "    \"\"\"\n",
    "    Compute and visualise the latent encodings for the MNIST dataset using a trained CNN autoencoder.\n",
    "    \n",
    "    Parameters:\n",
    "    x (array): Input data to be encoded.\n",
    "    y (array): Corresponding labels for the input data.\n",
    "    cnn_autoencoder (Model): Trained CNN autoencoder model.\n",
    "    n (int): Number of samples to visualize.\n",
    "    txt (str): Text for figure caption.\n",
    "    \"\"\"\n",
    "    # Commpute the trained latent encodings\n",
    "    cnn_encoder = cnn_autoencoder.get_layer('mnist_cnn_encoder')\n",
    "    trained_encodings = cnn_encoder(x).numpy()\n",
    "    \n",
    "    # Plot the latent encodings\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    for i in set(y):\n",
    "        plt.scatter(trained_encodings[:n][y[:n] == i, 0], \n",
    "                    trained_encodings[:n][y[:n] == i, 1], \n",
    "                    label=i, alpha=0.6)\n",
    "    plt.xlabel('Dim 1')\n",
    "    plt.ylabel('Dim 2')\n",
    "    plt.title('Latent Embeddings: MNIST')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    fig.text(.5, .001, txt, ha='center')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
